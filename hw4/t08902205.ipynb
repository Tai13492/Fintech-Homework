{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mpl_finance\n",
    "# import matplotlib.dates as mdates \n",
    "from talib import MA,STOCH\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_OF_2018 = 6044\n",
    "START_OF_2017 = 5793\n",
    "TIME_STEP = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_four = df[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\"]] 6046 -> 6044 (2018)\n",
    "# big_four_2018 = big_four[START_OF_2018:] 5795 -> 5793 (2017)\n",
    "# ax = plt.subplot()\n",
    "# mpl_finance.candlestick_ohlc(ax, big_four_2018, width=5, colorup='g', colordown='r')\n",
    "# ax.xaxis_date()\n",
    "# ax.grid(True)\n",
    "# plt.show()\n",
    "# date_2018 = df[START_OF_2018:][\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SPY.csv\",date_parser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[ df[\"Date\"]<'2017-01-01' ].copy()\n",
    "# df_validation = df[(df['Date'] >= '2017-01-01') & (df['Date'] < \"2018-01-01\")].copy()\n",
    "df_validation = df[df[\"Date\"] >= \"2017-01-01\"].copy()\n",
    "df_plot = df[df[\"Date\"] >= \"2018-01-01\"].copy()\n",
    "# df_validation.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_10_2018 = MA(df[START_OF_2018 - 10:][\"Close\"], timeperiod=10, matype=0)\n",
    "# ma_30_2018 = MA(df[START_OF_2018 - 30:][\"Close\"], timeperiod=30, matype=0)\n",
    "# df_2018_neg8 = df[START_OF_2018-8:]\n",
    "# k_2018, d_2018 = STOCH(df_2018_neg8[\"High\"], df_2018_neg8[\"Low\"], df_2018_neg8[\"Close\"], fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "\n",
    "# plt.plot(np.arange(len(ma_10_2018) - 10), ma_10_2018[10:], label=\"MA-10\")\n",
    "# plt.plot(np.arange(len(ma_30_2018) - 30), ma_30_2018[30:], label=\"MA-30\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Technical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_10_train = MA(df_train[\"Close\"], timeperiod=10, matype=0)\n",
    "ma_30_train = MA(df_train[\"Close\"], timeperiod=30, matype=0)\n",
    "k_train, d_train = STOCH(df_train[\"High\"], df_train[\"Low\"], df_train[\"Close\"],fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "df_train[\"MA10\"] = ma_10_train\n",
    "df_train[\"MA30\"] = ma_30_train\n",
    "df_train[\"K\"] = k_train\n",
    "df_train[\"D\"] = d_train\n",
    "\n",
    "ma_10_validation = MA(df_validation[\"Close\"], timeperiod=10, matype=0)\n",
    "ma_30_validation = MA(df_validation[\"Close\"], timeperiod=30, matype=0)\n",
    "k_validation, d_validation = STOCH(df_validation[\"High\"], df_validation[\"Low\"], df_validation[\"Close\"],fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "df_validation[\"MA10\"] = ma_10_validation\n",
    "df_validation[\"MA30\"] = ma_30_validation\n",
    "df_validation[\"K\"] = k_validation\n",
    "df_validation[\"D\"] = d_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop dates and NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(axis=0)\n",
    "df_train = df_train.drop([\"Date\"], axis=1)\n",
    "\n",
    "df_validation = df_validation.dropna(axis=0)\n",
    "df_validation = df_validation.drop([\"Date\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataframe(data_frame):\n",
    "    normalize_df = data_frame.copy()\n",
    "    for column in normalize_df.columns:\n",
    "        min_value = min(normalize_df[column])\n",
    "        max_value = max(normalize_df[column])\n",
    "        normalize_df[column] = (normalize_df[column] - min_value) / (max_value - min_value)\n",
    "    return normalize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = normalizeDataframe(df_train)\n",
    "df_validation = normalizeDataframe(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare X, y train and validation for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_train.values\n",
    "data_validation = df_validation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_validation = []\n",
    "y_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30,data_train.shape[0]):\n",
    "    X_train.append(data_train[i-30:i])\n",
    "    y_train.append(data_train[i, 0])\n",
    "\n",
    "for i in range(30, data_validation.shape[0]):\n",
    "    X_validation.append(data_validation[i-30:i])\n",
    "    y_validation.append(data_validation[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_validation, y_validation = np.array(X_validation), np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5734, 30, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressior = Sequential()\n",
    "regressior.add(LSTM(units = 32, activation = 'tanh', input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "regressior.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 32)                5504      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,537\n",
      "Trainable params: 5,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressior.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=\"best_params.hdf5\", monitor=\"val_loss\",verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressior.compile(optimizer='adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5734 samples, validate on 442 samples\n",
      "Epoch 1/128\n",
      "5568/5734 [============================>.] - ETA: 0s - loss: 0.0131\n",
      "Epoch 00001: val_loss improved from inf to 0.00653, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 5s 851us/sample - loss: 0.0128 - val_loss: 0.0065\n",
      "Epoch 2/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.4498e-04\n",
      "Epoch 00002: val_loss improved from 0.00653 to 0.00559, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 398us/sample - loss: 4.4334e-04 - val_loss: 0.0056\n",
      "Epoch 3/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 2.6244e-04\n",
      "Epoch 00003: val_loss improved from 0.00559 to 0.00500, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 395us/sample - loss: 2.6177e-04 - val_loss: 0.0050\n",
      "Epoch 4/128\n",
      "5568/5734 [============================>.] - ETA: 0s - loss: 1.9222e-04\n",
      "Epoch 00004: val_loss improved from 0.00500 to 0.00462, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 391us/sample - loss: 1.9217e-04 - val_loss: 0.0046\n",
      "Epoch 5/128\n",
      "5568/5734 [============================>.] - ETA: 0s - loss: 1.6654e-04\n",
      "Epoch 00005: val_loss improved from 0.00462 to 0.00438, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 394us/sample - loss: 1.6511e-04 - val_loss: 0.0044\n",
      "Epoch 6/128\n",
      "5568/5734 [============================>.] - ETA: 0s - loss: 1.4153e-04\n",
      "Epoch 00006: val_loss improved from 0.00438 to 0.00426, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 385us/sample - loss: 1.4081e-04 - val_loss: 0.0043\n",
      "Epoch 7/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 1.2691e-04\n",
      "Epoch 00007: val_loss improved from 0.00426 to 0.00422, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 383us/sample - loss: 1.2733e-04 - val_loss: 0.0042\n",
      "Epoch 8/128\n",
      "5568/5734 [============================>.] - ETA: 0s - loss: 1.1433e-04\n",
      "Epoch 00008: val_loss improved from 0.00422 to 0.00391, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 386us/sample - loss: 1.1428e-04 - val_loss: 0.0039\n",
      "Epoch 9/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 1.0395e-04\n",
      "Epoch 00009: val_loss improved from 0.00391 to 0.00369, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 402us/sample - loss: 1.0396e-04 - val_loss: 0.0037\n",
      "Epoch 10/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 9.8188e-05\n",
      "Epoch 00010: val_loss improved from 0.00369 to 0.00360, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 586us/sample - loss: 9.7301e-05 - val_loss: 0.0036\n",
      "Epoch 11/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 9.2233e-05\n",
      "Epoch 00011: val_loss improved from 0.00360 to 0.00344, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 390us/sample - loss: 9.1669e-05 - val_loss: 0.0034\n",
      "Epoch 12/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 8.2618e-05\n",
      "Epoch 00012: val_loss improved from 0.00344 to 0.00338, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 387us/sample - loss: 8.2293e-05 - val_loss: 0.0034\n",
      "Epoch 13/128\n",
      "5568/5734 [============================>.] - ETA: 0s - loss: 7.8954e-05\n",
      "Epoch 00013: val_loss improved from 0.00338 to 0.00330, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 389us/sample - loss: 7.8833e-05 - val_loss: 0.0033\n",
      "Epoch 14/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 7.5803e-05\n",
      "Epoch 00014: val_loss improved from 0.00330 to 0.00311, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 400us/sample - loss: 7.6173e-05 - val_loss: 0.0031\n",
      "Epoch 15/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 7.0719e-05\n",
      "Epoch 00015: val_loss improved from 0.00311 to 0.00304, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 396us/sample - loss: 7.0469e-05 - val_loss: 0.0030\n",
      "Epoch 16/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 6.5584e-05- ETA: 0s - los\n",
      "Epoch 00016: val_loss improved from 0.00304 to 0.00291, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 408us/sample - loss: 6.5618e-05 - val_loss: 0.0029\n",
      "Epoch 17/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 6.4512e-05\n",
      "Epoch 00017: val_loss improved from 0.00291 to 0.00289, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 400us/sample - loss: 6.4547e-05 - val_loss: 0.0029\n",
      "Epoch 18/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 5.9330e-05\n",
      "Epoch 00018: val_loss improved from 0.00289 to 0.00274, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 411us/sample - loss: 5.9289e-05 - val_loss: 0.0027\n",
      "Epoch 19/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.8974e-05\n",
      "Epoch 00019: val_loss improved from 0.00274 to 0.00262, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 414us/sample - loss: 5.8885e-05 - val_loss: 0.0026\n",
      "Epoch 20/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.4661e-05\n",
      "Epoch 00020: val_loss improved from 0.00262 to 0.00258, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 420us/sample - loss: 5.4607e-05 - val_loss: 0.0026\n",
      "Epoch 21/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.1243e-05\n",
      "Epoch 00021: val_loss improved from 0.00258 to 0.00248, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 418us/sample - loss: 5.1114e-05 - val_loss: 0.0025\n",
      "Epoch 22/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 5.3379e-05- ETA: \n",
      "Epoch 00022: val_loss improved from 0.00248 to 0.00245, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 424us/sample - loss: 5.3369e-05 - val_loss: 0.0024\n",
      "Epoch 23/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.0472e-05\n",
      "Epoch 00023: val_loss improved from 0.00245 to 0.00241, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 421us/sample - loss: 5.0299e-05 - val_loss: 0.0024\n",
      "Epoch 24/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 4.8278e-05\n",
      "Epoch 00024: val_loss improved from 0.00241 to 0.00224, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 417us/sample - loss: 4.8024e-05 - val_loss: 0.0022\n",
      "Epoch 25/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 4.7097e-05\n",
      "Epoch 00025: val_loss improved from 0.00224 to 0.00215, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 422us/sample - loss: 4.7149e-05 - val_loss: 0.0021\n",
      "Epoch 26/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.5520e-05\n",
      "Epoch 00026: val_loss improved from 0.00215 to 0.00212, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 434us/sample - loss: 4.5382e-05 - val_loss: 0.0021\n",
      "Epoch 27/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.2653e-05\n",
      "Epoch 00027: val_loss improved from 0.00212 to 0.00205, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 427us/sample - loss: 4.2760e-05 - val_loss: 0.0021\n",
      "Epoch 28/128\n",
      "5568/5734 [============================>.] - ETA: 0s - loss: 4.0039e-05\n",
      "Epoch 00028: val_loss improved from 0.00205 to 0.00194, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 427us/sample - loss: 4.0293e-05 - val_loss: 0.0019\n",
      "Epoch 29/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 4.2131e-05\n",
      "Epoch 00029: val_loss did not improve from 0.00194\n",
      "5734/5734 [==============================] - 3s 439us/sample - loss: 4.2078e-05 - val_loss: 0.0019\n",
      "Epoch 30/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.0189e-05\n",
      "Epoch 00030: val_loss improved from 0.00194 to 0.00192, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 2s 430us/sample - loss: 4.0082e-05 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 3.8086e-05\n",
      "Epoch 00031: val_loss improved from 0.00192 to 0.00182, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 440us/sample - loss: 3.7977e-05 - val_loss: 0.0018\n",
      "Epoch 32/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.1295e-05\n",
      "Epoch 00032: val_loss did not improve from 0.00182\n",
      "5734/5734 [==============================] - 3s 461us/sample - loss: 4.1119e-05 - val_loss: 0.0019\n",
      "Epoch 33/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 3.7657e-05\n",
      "Epoch 00033: val_loss improved from 0.00182 to 0.00176, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 487us/sample - loss: 3.7759e-05 - val_loss: 0.0018\n",
      "Epoch 34/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 3.8365e-05- ETA: 0s - los\n",
      "Epoch 00034: val_loss improved from 0.00176 to 0.00166, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 474us/sample - loss: 3.8754e-05 - val_loss: 0.0017\n",
      "Epoch 35/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.1147e-05\n",
      "Epoch 00035: val_loss improved from 0.00166 to 0.00164, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 494us/sample - loss: 4.1038e-05 - val_loss: 0.0016\n",
      "Epoch 36/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 3.4761e-05\n",
      "Epoch 00036: val_loss improved from 0.00164 to 0.00160, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 476us/sample - loss: 3.4944e-05 - val_loss: 0.0016\n",
      "Epoch 37/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 3.3632e-05\n",
      "Epoch 00037: val_loss improved from 0.00160 to 0.00158, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 494us/sample - loss: 3.3542e-05 - val_loss: 0.0016\n",
      "Epoch 38/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 3.1706e-05\n",
      "Epoch 00038: val_loss improved from 0.00158 to 0.00152, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 470us/sample - loss: 3.1661e-05 - val_loss: 0.0015\n",
      "Epoch 39/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 3.1976e-05\n",
      "Epoch 00039: val_loss improved from 0.00152 to 0.00147, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 475us/sample - loss: 3.1962e-05 - val_loss: 0.0015\n",
      "Epoch 40/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 3.0973e-05\n",
      "Epoch 00040: val_loss improved from 0.00147 to 0.00146, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 471us/sample - loss: 3.1378e-05 - val_loss: 0.0015\n",
      "Epoch 41/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.9231e-05\n",
      "Epoch 00041: val_loss improved from 0.00146 to 0.00143, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 494us/sample - loss: 2.9219e-05 - val_loss: 0.0014\n",
      "Epoch 42/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.7359e-05\n",
      "Epoch 00042: val_loss improved from 0.00143 to 0.00140, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 476us/sample - loss: 2.7350e-05 - val_loss: 0.0014\n",
      "Epoch 43/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.7155e-05\n",
      "Epoch 00043: val_loss improved from 0.00140 to 0.00139, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 598us/sample - loss: 2.7090e-05 - val_loss: 0.0014\n",
      "Epoch 44/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 2.6844e-05\n",
      "Epoch 00044: val_loss improved from 0.00139 to 0.00132, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 519us/sample - loss: 2.6677e-05 - val_loss: 0.0013\n",
      "Epoch 45/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.4970e-05\n",
      "Epoch 00045: val_loss improved from 0.00132 to 0.00129, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 479us/sample - loss: 2.4973e-05 - val_loss: 0.0013\n",
      "Epoch 46/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.6657e-05\n",
      "Epoch 00046: val_loss improved from 0.00129 to 0.00124, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 498us/sample - loss: 2.6552e-05 - val_loss: 0.0012\n",
      "Epoch 47/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.7488e-05\n",
      "Epoch 00047: val_loss improved from 0.00124 to 0.00121, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 494us/sample - loss: 2.7400e-05 - val_loss: 0.0012\n",
      "Epoch 48/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.4056e-05\n",
      "Epoch 00048: val_loss improved from 0.00121 to 0.00121, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 491us/sample - loss: 2.4202e-05 - val_loss: 0.0012\n",
      "Epoch 49/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.6139e-05\n",
      "Epoch 00049: val_loss improved from 0.00121 to 0.00121, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 488us/sample - loss: 2.6083e-05 - val_loss: 0.0012\n",
      "Epoch 50/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.4446e-05\n",
      "Epoch 00050: val_loss improved from 0.00121 to 0.00113, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 479us/sample - loss: 2.4432e-05 - val_loss: 0.0011\n",
      "Epoch 51/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.2768e-05\n",
      "Epoch 00051: val_loss improved from 0.00113 to 0.00111, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 475us/sample - loss: 2.2769e-05 - val_loss: 0.0011\n",
      "Epoch 52/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.4264e-05- ETA: 0s - loss: 2.5451e- - ETA: 0s - lo\n",
      "Epoch 00052: val_loss improved from 0.00111 to 0.00109, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 500us/sample - loss: 2.4210e-05 - val_loss: 0.0011\n",
      "Epoch 53/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.1830e-05\n",
      "Epoch 00053: val_loss improved from 0.00109 to 0.00106, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 505us/sample - loss: 2.1767e-05 - val_loss: 0.0011\n",
      "Epoch 54/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 2.4731e-05\n",
      "Epoch 00054: val_loss did not improve from 0.00106\n",
      "5734/5734 [==============================] - 3s 477us/sample - loss: 2.4894e-05 - val_loss: 0.0011\n",
      "Epoch 55/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.3650e-05\n",
      "Epoch 00055: val_loss improved from 0.00106 to 0.00103, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 462us/sample - loss: 2.3584e-05 - val_loss: 0.0010\n",
      "Epoch 56/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.6044e-05\n",
      "Epoch 00056: val_loss improved from 0.00103 to 0.00097, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 463us/sample - loss: 2.6210e-05 - val_loss: 9.7442e-04\n",
      "Epoch 57/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.2099e-05\n",
      "Epoch 00057: val_loss improved from 0.00097 to 0.00096, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 464us/sample - loss: 2.2038e-05 - val_loss: 9.5996e-04\n",
      "Epoch 58/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.8949e-05\n",
      "Epoch 00058: val_loss did not improve from 0.00096\n",
      "5734/5734 [==============================] - 3s 488us/sample - loss: 1.8851e-05 - val_loss: 9.8661e-04\n",
      "Epoch 59/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.1854e-05\n",
      "Epoch 00059: val_loss improved from 0.00096 to 0.00094, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 485us/sample - loss: 2.1812e-05 - val_loss: 9.3757e-04\n",
      "Epoch 60/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.5651e-05- ETA: 0s - loss: 2 - ETA: 0s - loss: 2.6165e\n",
      "Epoch 00060: val_loss improved from 0.00094 to 0.00091, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 474us/sample - loss: 2.5685e-05 - val_loss: 9.0932e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.7307e-05\n",
      "Epoch 00061: val_loss improved from 0.00091 to 0.00088, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 469us/sample - loss: 1.7460e-05 - val_loss: 8.7998e-04\n",
      "Epoch 62/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.8536e-05\n",
      "Epoch 00062: val_loss did not improve from 0.00088\n",
      "5734/5734 [==============================] - 3s 460us/sample - loss: 1.8534e-05 - val_loss: 8.8964e-04\n",
      "Epoch 63/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 2.1066e-05\n",
      "Epoch 00063: val_loss improved from 0.00088 to 0.00084, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 560us/sample - loss: 2.1289e-05 - val_loss: 8.4479e-04\n",
      "Epoch 64/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.1073e-05\n",
      "Epoch 00064: val_loss improved from 0.00084 to 0.00082, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 497us/sample - loss: 2.0999e-05 - val_loss: 8.2293e-04\n",
      "Epoch 65/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.9715e-05- ETA: 0s - loss: 2.044\n",
      "Epoch 00065: val_loss improved from 0.00082 to 0.00081, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 475us/sample - loss: 1.9692e-05 - val_loss: 8.1424e-04\n",
      "Epoch 66/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.6773e-05\n",
      "Epoch 00066: val_loss improved from 0.00081 to 0.00079, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 470us/sample - loss: 1.6843e-05 - val_loss: 7.9352e-04\n",
      "Epoch 67/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.7000e-05-\n",
      "Epoch 00067: val_loss improved from 0.00079 to 0.00077, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 473us/sample - loss: 1.6933e-05 - val_loss: 7.7348e-04\n",
      "Epoch 68/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.6771e-05\n",
      "Epoch 00068: val_loss improved from 0.00077 to 0.00077, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 583us/sample - loss: 1.6763e-05 - val_loss: 7.7041e-04\n",
      "Epoch 69/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.5311e-05\n",
      "Epoch 00069: val_loss improved from 0.00077 to 0.00076, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 484us/sample - loss: 1.5318e-05 - val_loss: 7.6241e-04\n",
      "Epoch 70/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.4589e-05\n",
      "Epoch 00070: val_loss improved from 0.00076 to 0.00072, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 482us/sample - loss: 1.4550e-05 - val_loss: 7.2465e-04\n",
      "Epoch 71/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.6926e-05- ETA: 1s\n",
      "Epoch 00071: val_loss did not improve from 0.00072\n",
      "5734/5734 [==============================] - 3s 471us/sample - loss: 1.6911e-05 - val_loss: 7.3826e-04\n",
      "Epoch 72/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.4923e-05\n",
      "Epoch 00072: val_loss improved from 0.00072 to 0.00069, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 480us/sample - loss: 1.4896e-05 - val_loss: 6.9045e-04\n",
      "Epoch 73/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.8915e-05\n",
      "Epoch 00073: val_loss did not improve from 0.00069\n",
      "5734/5734 [==============================] - 3s 461us/sample - loss: 1.8869e-05 - val_loss: 6.9753e-04\n",
      "Epoch 74/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.3002e-05\n",
      "Epoch 00074: val_loss improved from 0.00069 to 0.00066, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 468us/sample - loss: 1.2981e-05 - val_loss: 6.6202e-04\n",
      "Epoch 75/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.6467e-05- ETA: 0s - loss: \n",
      "Epoch 00075: val_loss improved from 0.00066 to 0.00064, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 488us/sample - loss: 1.6528e-05 - val_loss: 6.4185e-04\n",
      "Epoch 76/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.3158e-05\n",
      "Epoch 00076: val_loss did not improve from 0.00064\n",
      "5734/5734 [==============================] - 3s 473us/sample - loss: 1.3108e-05 - val_loss: 6.5214e-04\n",
      "Epoch 77/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.2922e-05\n",
      "Epoch 00077: val_loss did not improve from 0.00064\n",
      "5734/5734 [==============================] - 3s 473us/sample - loss: 1.2900e-05 - val_loss: 6.5203e-04\n",
      "Epoch 78/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.3811e-05- ETA: 1 - ETA: 0s - los\n",
      "Epoch 00078: val_loss improved from 0.00064 to 0.00060, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 475us/sample - loss: 1.3752e-05 - val_loss: 6.0435e-04\n",
      "Epoch 79/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.1961e-05\n",
      "Epoch 00079: val_loss improved from 0.00060 to 0.00059, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 477us/sample - loss: 1.1938e-05 - val_loss: 5.9489e-04\n",
      "Epoch 80/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.4744e-05- ET\n",
      "Epoch 00080: val_loss improved from 0.00059 to 0.00059, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 472us/sample - loss: 1.4718e-05 - val_loss: 5.9085e-04\n",
      "Epoch 81/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 1.1537e-05- ETA: 1s\n",
      "Epoch 00081: val_loss improved from 0.00059 to 0.00056, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 508us/sample - loss: 1.1631e-05 - val_loss: 5.6255e-04\n",
      "Epoch 82/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.4862e-05\n",
      "Epoch 00082: val_loss improved from 0.00056 to 0.00056, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 480us/sample - loss: 1.4916e-05 - val_loss: 5.5559e-04\n",
      "Epoch 83/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.1783e-05\n",
      "Epoch 00083: val_loss did not improve from 0.00056\n",
      "5734/5734 [==============================] - 3s 478us/sample - loss: 1.1757e-05 - val_loss: 5.6000e-04\n",
      "Epoch 84/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.2544e-05\n",
      "Epoch 00084: val_loss improved from 0.00056 to 0.00053, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 484us/sample - loss: 1.2500e-05 - val_loss: 5.3444e-04\n",
      "Epoch 85/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.1773e-05- ETA: 0s - loss: 1.1986e\n",
      "Epoch 00085: val_loss improved from 0.00053 to 0.00053, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 478us/sample - loss: 1.1729e-05 - val_loss: 5.3155e-04\n",
      "Epoch 86/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.1578e-05- ETA: 0s - loss: 1\n",
      "Epoch 00086: val_loss improved from 0.00053 to 0.00052, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 495us/sample - loss: 1.1531e-05 - val_loss: 5.1859e-04\n",
      "Epoch 87/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.0698e-05\n",
      "Epoch 00087: val_loss improved from 0.00052 to 0.00051, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 516us/sample - loss: 1.0662e-05 - val_loss: 5.0807e-04\n",
      "Epoch 88/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 9.3003e-06- ETA: 2 - ETA: 1s -\n",
      "Epoch 00088: val_loss did not improve from 0.00051\n",
      "5734/5734 [==============================] - 3s 489us/sample - loss: 9.4821e-06 - val_loss: 5.1292e-04\n",
      "Epoch 89/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.1735e-05\n",
      "Epoch 00089: val_loss improved from 0.00051 to 0.00050, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 4s 637us/sample - loss: 1.1810e-05 - val_loss: 4.9781e-04\n",
      "Epoch 90/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.0220e-05\n",
      "Epoch 00090: val_loss improved from 0.00050 to 0.00047, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 478us/sample - loss: 1.0256e-05 - val_loss: 4.7073e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.1381e-05\n",
      "Epoch 00091: val_loss improved from 0.00047 to 0.00047, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 479us/sample - loss: 1.1337e-05 - val_loss: 4.6876e-04\n",
      "Epoch 92/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.0299e-05\n",
      "Epoch 00092: val_loss improved from 0.00047 to 0.00047, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 502us/sample - loss: 1.0313e-05 - val_loss: 4.6521e-04\n",
      "Epoch 93/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 9.0439e-06\n",
      "Epoch 00093: val_loss improved from 0.00047 to 0.00045, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 493us/sample - loss: 9.0685e-06 - val_loss: 4.5254e-04\n",
      "Epoch 94/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 8.5827e-06\n",
      "Epoch 00094: val_loss improved from 0.00045 to 0.00045, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 493us/sample - loss: 8.6338e-06 - val_loss: 4.4745e-04\n",
      "Epoch 95/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 9.0570e-06- ETA: 0s - lo\n",
      "Epoch 00095: val_loss did not improve from 0.00045\n",
      "5734/5734 [==============================] - 3s 477us/sample - loss: 9.0500e-06 - val_loss: 4.4826e-04\n",
      "Epoch 96/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 7.2668e-06- ETA: 1s - los - ETA: 0s - loss: 7.\n",
      "Epoch 00096: val_loss improved from 0.00045 to 0.00042, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 484us/sample - loss: 7.3053e-06 - val_loss: 4.2028e-04\n",
      "Epoch 97/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.0030e-05\n",
      "Epoch 00097: val_loss improved from 0.00042 to 0.00041, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 485us/sample - loss: 1.0027e-05 - val_loss: 4.1016e-04\n",
      "Epoch 98/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 6.8796e-06\n",
      "Epoch 00098: val_loss did not improve from 0.00041\n",
      "5734/5734 [==============================] - 3s 525us/sample - loss: 6.8990e-06 - val_loss: 4.1924e-04\n",
      "Epoch 99/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 7.4634e-06\n",
      "Epoch 00099: val_loss improved from 0.00041 to 0.00039, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 500us/sample - loss: 7.4970e-06 - val_loss: 3.9467e-04\n",
      "Epoch 100/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 7.3062e-06\n",
      "Epoch 00100: val_loss did not improve from 0.00039\n",
      "5734/5734 [==============================] - 3s 496us/sample - loss: 7.2984e-06 - val_loss: 3.9858e-04\n",
      "Epoch 101/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 7.6496e-06\n",
      "Epoch 00101: val_loss improved from 0.00039 to 0.00038, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 503us/sample - loss: 7.6277e-06 - val_loss: 3.8153e-04\n",
      "Epoch 102/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 1.0118e-05- ETA: 1s -\n",
      "Epoch 00102: val_loss did not improve from 0.00038\n",
      "5734/5734 [==============================] - 3s 493us/sample - loss: 1.0107e-05 - val_loss: 3.9446e-04\n",
      "Epoch 103/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 6.7037e-06- ETA: 0s - loss: 6.6724e-0\n",
      "Epoch 00103: val_loss improved from 0.00038 to 0.00038, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 529us/sample - loss: 6.6658e-06 - val_loss: 3.7773e-04\n",
      "Epoch 104/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 8.4205e-06\n",
      "Epoch 00104: val_loss improved from 0.00038 to 0.00037, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 540us/sample - loss: 8.3945e-06 - val_loss: 3.6601e-04\n",
      "Epoch 105/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 6.4387e-06\n",
      "Epoch 00105: val_loss did not improve from 0.00037\n",
      "5734/5734 [==============================] - 3s 506us/sample - loss: 6.4190e-06 - val_loss: 3.7182e-04\n",
      "Epoch 106/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.9332e-06\n",
      "Epoch 00106: val_loss improved from 0.00037 to 0.00035, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 505us/sample - loss: 5.9693e-06 - val_loss: 3.4827e-04\n",
      "Epoch 107/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.6390e-06\n",
      "Epoch 00107: val_loss improved from 0.00035 to 0.00034, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 494us/sample - loss: 5.6200e-06 - val_loss: 3.4497e-04\n",
      "Epoch 108/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 6.2044e-06\n",
      "Epoch 00108: val_loss improved from 0.00034 to 0.00034, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 503us/sample - loss: 6.1818e-06 - val_loss: 3.4011e-04\n",
      "Epoch 109/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.4464e-06\n",
      "Epoch 00109: val_loss did not improve from 0.00034\n",
      "5734/5734 [==============================] - 3s 514us/sample - loss: 5.4576e-06 - val_loss: 3.4366e-04\n",
      "Epoch 110/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.8550e-0 - ETA: 0s - loss: 5.8601e-06\n",
      "Epoch 00110: val_loss improved from 0.00034 to 0.00033, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 509us/sample - loss: 5.8482e-06 - val_loss: 3.3246e-04\n",
      "Epoch 111/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 8.2918e-06\n",
      "Epoch 00111: val_loss improved from 0.00033 to 0.00033, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 511us/sample - loss: 8.3061e-06 - val_loss: 3.2550e-04\n",
      "Epoch 112/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.8059e-06\n",
      "Epoch 00112: val_loss improved from 0.00033 to 0.00032, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 509us/sample - loss: 4.8115e-06 - val_loss: 3.2031e-04\n",
      "Epoch 113/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.1877e-06\n",
      "Epoch 00113: val_loss improved from 0.00032 to 0.00032, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 513us/sample - loss: 5.2141e-06 - val_loss: 3.1994e-04\n",
      "Epoch 114/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.9573e-06\n",
      "Epoch 00114: val_loss improved from 0.00032 to 0.00031, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 538us/sample - loss: 4.9510e-06 - val_loss: 3.1229e-04\n",
      "Epoch 115/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.3350e-06\n",
      "Epoch 00115: val_loss did not improve from 0.00031\n",
      "5734/5734 [==============================] - 3s 519us/sample - loss: 4.3412e-06 - val_loss: 3.1562e-04\n",
      "Epoch 116/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.2389e-06- ETA: 0s - loss: 3.\n",
      "Epoch 00116: val_loss improved from 0.00031 to 0.00030, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 518us/sample - loss: 4.2412e-06 - val_loss: 3.0256e-04\n",
      "Epoch 117/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.5072e-06\n",
      "Epoch 00117: val_loss did not improve from 0.00030\n",
      "5734/5734 [==============================] - 3s 501us/sample - loss: 5.5816e-06 - val_loss: 3.0821e-04\n",
      "Epoch 118/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.3227e-06\n",
      "Epoch 00118: val_loss improved from 0.00030 to 0.00030, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 498us/sample - loss: 4.3191e-06 - val_loss: 2.9971e-04\n",
      "Epoch 119/128\n",
      "5632/5734 [============================>.] - ETA: 0s - loss: 3.9412e-06\n",
      "Epoch 00119: val_loss did not improve from 0.00030\n",
      "5734/5734 [==============================] - 3s 513us/sample - loss: 3.9894e-06 - val_loss: 3.0994e-04\n",
      "Epoch 120/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 6.6060e-06- ETA: 2s - loss: 5.7893e\n",
      "Epoch 00120: val_loss improved from 0.00030 to 0.00029, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 536us/sample - loss: 6.5753e-06 - val_loss: 2.8909e-04\n",
      "Epoch 121/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5696/5734 [============================>.] - ETA: 0s - loss: 3.9459e-06- ETA: 0s - loss: 3.6288e\n",
      "Epoch 00121: val_loss did not improve from 0.00029\n",
      "5734/5734 [==============================] - 3s 502us/sample - loss: 3.9383e-06 - val_loss: 2.9435e-04\n",
      "Epoch 122/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.7901e-06- ETA: 2s - loss: - \n",
      "Epoch 00122: val_loss improved from 0.00029 to 0.00029, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 500us/sample - loss: 4.7788e-06 - val_loss: 2.8637e-04\n",
      "Epoch 123/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.8901e-06- ETA: 2 - ETA: 1s - loss: 2.9018e-0 - ETA: 1s - loss: 2.8897e- - ETA: 0s - \n",
      "Epoch 00123: val_loss improved from 0.00029 to 0.00028, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 499us/sample - loss: 2.8956e-06 - val_loss: 2.8313e-04\n",
      "Epoch 124/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.0804e-06\n",
      "Epoch 00124: val_loss did not improve from 0.00028\n",
      "5734/5734 [==============================] - 3s 490us/sample - loss: 4.1183e-06 - val_loss: 2.9144e-04\n",
      "Epoch 125/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.2118e-06\n",
      "Epoch 00125: val_loss improved from 0.00028 to 0.00028, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 4s 707us/sample - loss: 4.2028e-06 - val_loss: 2.8074e-04\n",
      "Epoch 126/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 2.7857e-06- ETA: 0s - loss: 2.5\n",
      "Epoch 00126: val_loss improved from 0.00028 to 0.00028, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 580us/sample - loss: 2.8004e-06 - val_loss: 2.7804e-04\n",
      "Epoch 127/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 4.9795e-06\n",
      "Epoch 00127: val_loss improved from 0.00028 to 0.00027, saving model to best_params.hdf5\n",
      "5734/5734 [==============================] - 3s 490us/sample - loss: 4.9599e-06 - val_loss: 2.7280e-04\n",
      "Epoch 128/128\n",
      "5696/5734 [============================>.] - ETA: 0s - loss: 5.3068e-06\n",
      "Epoch 00128: val_loss did not improve from 0.00027\n",
      "5734/5734 [==============================] - 3s 475us/sample - loss: 5.3140e-06 - val_loss: 2.8459e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f198c5a788>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressior.fit(X_train, y_train, epochs=128, batch_size=64, validation_data = (X_validation, y_validation),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_10_2017 = MA(df[START_OF_2017 - 10 : START_OF_2018][\"Close\"], timeperiod=10, matype=0)\n",
    "# ma_30_2017 = MA(df[START_OF_2017 - 30 : START_OF_2018][\"Close\"], timeperiod=30, matype=0)\n",
    "# df_2017_neg8 = df[START_OF_2017 - 8 : START_OF_2018]\n",
    "# k_2017, d_2017 = STOCH(df_2017_neg8[\"High\"], df_2017_neg8[\"Low\"], df_2017_neg8[\"Close\"], fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5793\n",
      "5793\n",
      "5793\n",
      "5793\n"
     ]
    }
   ],
   "source": [
    "# def removeNanFromNumpyArray(numpy_array):\n",
    "#     temp = numpy_array.copy()\n",
    "#     temp = temp[np.logical_not(np.isnan(temp))]\n",
    "#     return temp\n",
    "# print(len(ma_10_train))\n",
    "# print(len(ma_30_train))\n",
    "# print(len(k_train))\n",
    "# print(len(d_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_10_train = removeNanFromNumpyArray(ma_10_train)\n",
    "# ma_30_train = removeNanFromNumpyArray(ma_30_train)\n",
    "# k_train = removeNanFromNumpyArray(k_train)\n",
    "# d_train = removeNanFromNumpyArray(d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalizeNumpyArray(numpy_array):\n",
    "#     min_val = min(numpy_array)\n",
    "#     max_val = max(numpy_array)\n",
    "#     normalize_equation = lambda x: (x - min_val)/(max_val - min_val)\n",
    "#     normalized_numpy_array = np.array([normalize_equation(x) for x in numpy_array])\n",
    "#     return normalized_numpy_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_10_train = normalizeNumpyArray(ma_10_train)\n",
    "# ma_30_train = normalizeNumpyArray(ma_30_train)\n",
    "# k_train = normalizeNumpyArray(k_train)\n",
    "# d_train = normalizeNumpyArray(d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5784\n",
      "5764\n",
      "5785\n",
      "5785\n",
      "(5793, 7)\n"
     ]
    }
   ],
   "source": [
    "# print(len(ma_10_train))\n",
    "# print(len(ma_30_train))\n",
    "# print(len(k_train))\n",
    "# print(len(d_train))\n",
    "# print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_10_train = ma_10_train[20:]\n",
    "# k_train = k_train[21:]\n",
    "# d_train = d_train[21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5764\n",
      "5764\n",
      "5764\n",
      "5764\n"
     ]
    }
   ],
   "source": [
    "# print(len(ma_10_train))\n",
    "# print(len(ma_30_train))\n",
    "# print(len(k_train))\n",
    "# print(len(d_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
